{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94979c09-9327-4968-9441-6f9e01e2756b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (functions.py, line 69)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/ID2221/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3526\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\n\u001b[0;31m    from functions import util\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/ID2221/lib/python3.9/site-packages/functions.py:69\u001b[0;36m\u001b[0m\n\u001b[0;31m    nodes = tuple(map(lambda (k, v): process_node(inner, k, v),\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d340d5a7-7a8a-4c52-9b96-e450c9dc6f1b",
   "metadata": {},
   "source": [
    "## Weather Data Ingestion into Hopsworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5978d514-6904-4188-8be0-f1a8522f0fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "csv_file=Path(\"./guangzhou-air-quality.csv\")\n",
    "if csv_file.is_file():\n",
    "    print(\"File exists\")\n",
    "else:\n",
    "    print(\"Not exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58f5b95-e91b-4891-afe6-5986a4c9733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country=\"china\"\n",
    "city = \"guangzhou\"\n",
    "aqicn_url=\"https://api.waqi.info/feed/@1449\"\n",
    "\n",
    "# This API call may fail if the IP address you run this notebook from is blocked by the Nominatim API\n",
    "# If this fails, lookup the latitude, longitude using Google and enter the values here.\n",
    "latitude, longitude = 23.1291, 113.2644\n",
    "\n",
    "today = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ddbe566-0b54-4b64-a288-2c663d08ae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists\n"
     ]
    }
   ],
   "source": [
    "aqi_api_key_file = Path(\"./aqi-api-key.txt\")\n",
    "if csv_file.is_file():\n",
    "    print(\"File exists\")\n",
    "else:\n",
    "    print(\"Not exists\")\n",
    "\n",
    "with open(aqi_api_key_file, 'r') as file:\n",
    "    AQI_API_KEY = file.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11310d86-90c2-4942-836d-17d8965c96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hopsworks-api-key.txt', 'r') as file:\n",
    "     os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()\n",
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7168e8-9477-459d-8d70-0df3d46a6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df[['Sex','Age','Pclass','Fare','Parch','SibSp','Embarked', 'Survived']]\n",
    "#fill NAs with some imputed values\n",
    "def_values = {'Age': titanic_df['Age'].mean(), 'Embarked': titanic_df['Embarked'].value_counts().idxmax()}\n",
    "titanic_df = titanic_df.fillna(value=def_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c200d5-d2c9-48bf-8f5d-7a52b861225e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureStoreException",
     "evalue": "Provided primary key(s) pm25,so2,pm10,co,no2,o3 doesn't exist in feature dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m weather_fg \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mget_or_create_feature_group(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                             version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m                                             description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeather Daily Updates\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                             primary_key\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpm25\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpm10\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mso2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m                                             event_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m                                            )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mweather_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweather_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ID2221/lib/python3.9/site-packages/hsfs/feature_group.py:2528\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[0;34m(self, features, overwrite, operation, storage, write_options, validation_options, save_code, wait)\u001b[0m\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m write_options:\n\u001b[1;32m   2526\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait\n\u001b[0;32m-> 2528\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_code \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   2538\u001b[0m     ge_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ge_report\u001b[38;5;241m.\u001b[39mingestion_result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINGESTED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2539\u001b[0m ):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_engine\u001b[38;5;241m.\u001b[39msave_code(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ID2221/lib/python3.9/site-packages/hsfs/core/feature_group_engine.py:91\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[0;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m dataframe_features \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mparse_schema_feature_group(\n\u001b[1;32m     86\u001b[0m     feature_dataframe, feature_group\u001b[38;5;241m.\u001b[39mtime_travel_format\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39m_id:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# only save metadata if feature group does not exist\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_feature_group_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_options\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_schema_compatibility(\n\u001b[1;32m     97\u001b[0m         feature_group\u001b[38;5;241m.\u001b[39mfeatures, dataframe_features\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ID2221/lib/python3.9/site-packages/hsfs/core/feature_group_engine.py:340\u001b[0m, in \u001b[0;36mFeatureGroupEngine.save_feature_group_metadata\u001b[0;34m(self, feature_group, dataframe_features, write_options)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_schema_compatibility(\n\u001b[1;32m    335\u001b[0m         feature_group\u001b[38;5;241m.\u001b[39mfeatures, dataframe_features\n\u001b[1;32m    336\u001b[0m     )\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# set primary and partition key columns\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# we should move this to the backend\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_attribute_key_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feat\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39mprimary_key:\n",
      "File \u001b[0;32m~/miniconda3/envs/ID2221/lib/python3.9/site-packages/hsfs/util.py:333\u001b[0m, in \u001b[0;36mverify_attribute_key_names\u001b[0;34m(feature_group_obj, external_feature_group)\u001b[0m\n\u001b[1;32m    331\u001b[0m     diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(feature_group_obj\u001b[38;5;241m.\u001b[39mprimary_key) \u001b[38;5;241m-\u001b[39m feature_names\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mFeatureStoreException(\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided primary key(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist in feature dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_group_obj\u001b[38;5;241m.\u001b[39mevent_time:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_group_obj\u001b[38;5;241m.\u001b[39mevent_time \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m feature_names:\n",
      "\u001b[0;31mFeatureStoreException\u001b[0m: Provided primary key(s) pm25,so2,pm10,co,no2,o3 doesn't exist in feature dataframe"
     ]
    }
   ],
   "source": [
    "weather_fg = fs.get_or_create_feature_group(name=\"weather\",\n",
    "                                            version=1,\n",
    "                                            description=\"Weather Daily Updates\",\n",
    "                                            primary_key=[],\n",
    "                                            event_time='date'\n",
    "                                           )\n",
    "weather_fg.insert(weather_df) # write Pandas DataFrame to Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbc2c7-3854-4f21-ab39-b38e0aed6595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
